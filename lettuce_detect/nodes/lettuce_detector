#!/usr/bin/env python

import sys
import time
import math
import random
import rospy
import cv2
import cv2.aruco as aruco
import tf2_ros
import tf2_geometry_msgs
import numpy
from std_msgs.msg import String, Bool
from vegebot_msgs.msg import LettuceHypothesis, MarkerCorners, CalibrationRecords
from geometry_msgs.msg import Pose, Point, PointStamped
from sensor_msgs.msg import Image, CompressedImage, CameraInfo
from cv_bridge import CvBridge, CvBridgeError
from image_geometry import PinholeCameraModel

NODE_NAME = 'lettuce_detector'

LETTUCE_RADIUS = 0.05
LETTUCE_X_OFFSET = 0.7
LETTUCE_X_SPACING = 0.3
LETTUCE_Y_SPACING = 0.3
LETTUCE_Z_OFFSET = LETTUCE_RADIUS

LETTUCE_CAMERA_INFO_TOPIC_NAME = '/camera1/usb_cam/camera_info'
#LETTUCE_IMAGE_TOPIC_NAME = '/vegebot/lettuce_video/raw_images'
LETTUCE_IMAGE_TOPIC_NAME = '/camera1/usb_cam/image_raw'
LETTUCE_HYPOTHESIS_TOPIC_NAME = '/vegebot/lettuce_hypotheses'
LETTUCE_ANNOTATED_IMAGES_TOPIC_NAME = '/vegebot/lettuce_hypotheses/annotated_images'
LETTUCE_UPDATES_FROM_VIEWPORT_TOPIC_NAME = '/vegebot/lettuce_hypotheses/updates_from_viewport'
MARKER_CORNERS_TOPIC_NAME = '/vegebot/marker'
CALIBRATION_RECORDS_TOPIC_NAME = '/vegebot/calibration'

LETTUCE_IMAGE_TEST_FILE = '/home/simonbirrell/catkin_ws/src/vegebot/lettuce_test/nodes/lettuce_test.jpg'
LETTUCE_CASCADE_FILE = '/home/simonbirrell/catkin_ws/src/vegebot/lettuce_detect/cascade_data/cascade.xml' 

DEFAULT_FAKE_PROBABILITY = 0.8
DEFAULT_FAKE_LABEL = 'healthy'

# Use degrees as more intuitive
FIELD_HEIGHT_ANGLE = 30
FIELD_WIDTH_ANGLE = 50
# 
FIELD_PIXEL_WIDTH = 640
FIELD_PIXEL_HEIGHT = 480

FIELD_WIDTH_ANGLE_PARAM = '/vegebot/camera/field_width_angle'
FIELD_HEIGHT_ANGLE_PARAM = '/vegebot/camera/field_height_angle'

Lettuce_hypothesis_topic = None
Lettuce_images_raw_topic = None
Lettuce_images_annotated_topic = None
Lettuce_cascade = None
Lettuce_updates_from_viewport_topic = None
Marker_corners_topic = None
Overhead_camera_info = None
Overhead_camera_model = None

Last_lettuce_id = 0

Last_snapshot = 0
OpenCVBridge = 0

TfBuffer = None

Latest_calibration_records = None
USE_CALIBRATION_RECORDS = True
ARUCO_OFFSET_X = 0.26
ARUCO_OFFSET_Y = 0.10

########################### ROS Stuff ############################################

def subscribe_to_camera_info():
    rospy.loginfo("Subscribing to camera info")
    rospy.Subscriber(LETTUCE_CAMERA_INFO_TOPIC_NAME, CameraInfo, receive_camera_info)

def set_up_calibration_records_topic():
    rospy.loginfo("Subscribing to vegebot calibration records")
    rospy.Subscriber(CALIBRATION_RECORDS_TOPIC_NAME, CalibrationRecords, receive_calibration_records)

def receive_calibration_records(message):
    global Latest_calibration_records
    rospy.loginfo("-------- Received calibration records ---------")
    Latest_calibration_records = message
    rospy.loginfo(message)
    rospy.loginfo("-----------------------------------------------")

def receive_camera_info(camera_info_message):
    global Overhead_camera_model

    rospy.loginfo("Camera info received !!!!!")
    Overhead_camera_info = camera_info_message
    Overhead_camera_model = PinholeCameraModel()
    Overhead_camera_model.fromCameraInfo(camera_info_message)  

def subscribe_to_lettuce_updates_from_viewport():
    global Lettuce_updates_from_viewport_topic
    rospy.loginfo("Subscribing to updates")
    Lettuce_updates_from_viewport_topic = rospy.Subscriber(LETTUCE_UPDATES_FROM_VIEWPORT_TOPIC_NAME,
                                                            LettuceHypothesis,
                                                            receive_lettuce_from_viewport_update)

def receive_lettuce_from_viewport_update(lettuce_hypothesis_message):
    rospy.loginfo("********** GOT AN UPDATE FROM VIEWPORT ************")
    rospy.loginfo(lettuce_hypothesis_message)
    hypothesis = LettuceHypothesisComplete([(lettuce_hypothesis_message.camera_bb_x - (lettuce_hypothesis_message.camera_bb_width/2.0)) * FIELD_PIXEL_WIDTH,
                                            (lettuce_hypothesis_message.camera_bb_y - (lettuce_hypothesis_message.camera_bb_height/2.0))* FIELD_PIXEL_HEIGHT,
                                            lettuce_hypothesis_message.camera_bb_width * FIELD_PIXEL_WIDTH,
                                            lettuce_hypothesis_message.camera_bb_height * FIELD_PIXEL_HEIGHT], 
                                            lettuce_hypothesis_message.label, 
                                            lettuce_hypothesis_message.probability,
                                            lettuce_hypothesis_message.lettuce_hypothesis_id)
    rospy.loginfo("Publish lettuce hypothesis from update")
    hypothesis.publish()
    rospy.loginfo("published.")

def subscribe_to_lettuce_images_raw_topic(callback):
    global Lettuce_images_raw_topic   
    Lettuce_images_raw_topic = rospy.Subscriber(LETTUCE_IMAGE_TOPIC_NAME,
                           Image,
                           callback)

def get_camera_params():
    global FIELD_WIDTH_ANGLE, FIELD_HEIGHT_ANGLE, FIELD_WIDTH_ANGLE_PARAM, FIELD_HEIGHT_ANGLE_PARAM
    FIELD_WIDTH_ANGLE = rospy.get_param(FIELD_WIDTH_ANGLE_PARAM)    
    FIELD_HEIGHT_ANGLE = rospy.get_param(FIELD_HEIGHT_ANGLE_PARAM)    
    #rospy.loginfo("Read PARAM")
    #rospy.loginfo(FIELD_PIXEL_WIDTH)

def process_incoming_image(message):
    cv2_image = image_message_to_cv2_image(message)
    gray_cv2_image = cv2.cvtColor(cv2_image, cv2.COLOR_BGR2GRAY)

    annotated_cv2_image = look_for_lettuces(cv2_image, gray_cv2_image)
    annotated_cv2_image = look_for_aruco(gray_cv2_image, annotated_cv2_image)
    rospy.loginfo("Lettuce detector has processed an image!")   
    publish_annotated_image(annotated_cv2_image)

def look_for_lettuces(cv2_image, gray_cv2_image):
    global FIELD_PIXEL_WIDTH, FIELD_PIXEL_HEIGHT, FIELD_WIDTH_ANGLE, FIELD_HEIGHT_ANGLE
    #print("Received image for detection!")
    get_camera_params()
    #rospy.loginfo("Now it-s")
    #rospy.loginfo(FIELD_WIDTH_ANGLE)
    height, width, channels = cv2_image.shape
    FIELD_PIXEL_WIDTH = width
    FIELD_PIXEL_HEIGHT = height
    hypotheses = detect_lettuce_hypotheses_2D(gray_cv2_image)
    annotated_cv2_image = annotate_image(cv2_image, hypotheses)
    publish_camera_projection()
    for hypothesis in hypotheses:
        # Renable next lines to publish hypothesis
        #lettuce_hypothesis_message = transform_2D_hypothesis_to_3D(hypothesis)
        #Lettuce_hypothesis_topic.publish(lettuce_hypothesis_message)
        #hypothesis.publish()
        print("Publish lettuce hypothesis")
    return annotated_cv2_image    

def look_for_aruco(gray_cv2_image, annotated_cv2_image):
    aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)
    parameters =  aruco.DetectorParameters_create()
    corners, ids, rejectedImgPoints = aruco.detectMarkers(gray_cv2_image, aruco_dict, parameters=parameters)
    centroid = get_marker_centroid(corners)
    annotated_cv2_image = aruco.drawDetectedMarkers(annotated_cv2_image, corners)
    annotated_cv2_image = draw_centroid(annotated_cv2_image, centroid)
    publish_marker_corners(corners, centroid)
    return annotated_cv2_image    

def draw_centroid(annotated_cv2_image, centroid):
    if (centroid != None):
        radius = 4
        colour = (0, 255, 0)
        thickness = -4 # filled circle if negative
        cv2.circle(annotated_cv2_image, centroid, radius, colour, thickness)
    return annotated_cv2_image

def get_marker_centroid(corners):
    if (len(corners)>0):
        corners = corners[0][0]
        centroid = get_centroid_polygon([(corners[0][0], corners[0][1]), (corners[1][0], corners[1][1]), (corners[2][0], corners[2][1]), (corners[3][0], corners[3][1])])
        return centroid
    else:
        return None

def get_centroid_polygon(vertices):
    x = 0
    y = 0
    n = len(vertices)
    for vertex in vertices:
        x = x + vertex[0]
        y = y + vertex[1]
    x = x / n
    y = y / n    
    return (int(x), int(y))      

def set_up_marker_corners_topic():
    global Marker_corners_topic
    Marker_corners_topic = rospy.Publisher(MARKER_CORNERS_TOPIC_NAME,
                           MarkerCorners,
                           queue_size=10)
    return Marker_corners_topic

def publish_marker_corners(corners, centroid):
    global Marker_corners_topic

    marker_corners_message = MarkerCorners()
    if (len(corners)>0):
        marker_corners_message.detected = True
        corners = corners[0][0]
        marker_corners_message.x1 = corners[0][0]
        marker_corners_message.y1 = corners[0][1]
        marker_corners_message.x2 = corners[1][0]
        marker_corners_message.y2 = corners[1][1]
        marker_corners_message.x3 = corners[2][0]
        marker_corners_message.y3 = corners[2][1]
        marker_corners_message.x4 = corners[3][0]
        marker_corners_message.y4 = corners[3][1]
        marker_corners_message.cx = centroid[0]
        marker_corners_message.cy = centroid[1]
    else:
        marker_corners_message.detected = False    
    Marker_corners_topic.publish(marker_corners_message)    


def set_up_lettuce_hypotheses_topic():
    global Lettuce_hypothesis_topic
    Lettuce_hypothesis_topic = rospy.Publisher(LETTUCE_HYPOTHESIS_TOPIC_NAME,
                           LettuceHypothesis,
                           queue_size=10)
    return Lettuce_hypothesis_topic

def set_up_lettuce_images_annotated_topic():
    global Lettuce_images_annotated_topic
    Lettuce_images_annotated_topic = rospy.Publisher(LETTUCE_ANNOTATED_IMAGES_TOPIC_NAME,
                           Image,
                           queue_size=10)
    return Lettuce_images_annotated_topic

def publish_annotated_image(annotated_image):
    global Lettuce_images_annotated_topic
    annotated_image_message = image_to_image_message(annotated_image)
    Lettuce_images_annotated_topic.publish(annotated_image_message)

def subscribe_to_transforms():
    global TfBuffer

    TfBuffer = tf2_ros.Buffer()
    listener = tf2_ros.TransformListener(TfBuffer)

def get_camera_to_world_transform():
    if TfBuffer==None:
        return None
    try:
        #trans = TfBuffer.lookup_transform('world', 'camera_link', rospy.Time())
        trans = TfBuffer.lookup_transform('world', 'overhead_camera', rospy.Time())
    except (tf2_ros.LookupException, tf2_ros.ConnectivityException, tf2_ros.ExtrapolationException):
        print("*** WARNING: Transform buffer in lettuce_detector not ready ***")
        return None
    return trans    

def get_world_to_camera_transform():
    if TfBuffer==None:
        return None
    try:
        #trans = TfBuffer.lookup_transform('world', 'camera_link', rospy.Time())
        trans = TfBuffer.lookup_transform('overhead_camera', 'world', rospy.Time())
    except (tf2_ros.LookupException, tf2_ros.ConnectivityException, tf2_ros.ExtrapolationException):
        print("*** WARNING: Transform buffer in lettuce_detector not ready ***")
        return None
    return trans    


##################################################################################

########################### Imagery ##############################################

def set_up_opencv():
    global OpenCVBridge, Lettuce_cascade
    Lettuce_cascade = cv2.CascadeClassifier(LETTUCE_CASCADE_FILE)
    OpenCVBridge = CvBridge()

# lettuce_hypothesis_2D
# [id, bounding_box, label, probability]
#  where
# id is a GUID for the lettuce hypothesis
# bounding_box is [x,y,w,h] on image
# label is a string: 'healthy' etc.
# probability is a float from 0.0 to 1.0

def detect_lettuce_hypotheses_2D(gray_cv2_image):
    global Lettuce_cascade
    #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    lettuces = Lettuce_cascade.detectMultiScale(gray_cv2_image, 1.3, 5, 
                                                minSize=(60,60), maxSize=(250,250))

    lettuces = map(bounding_box_to_hypothesis, lettuces)
    # print("=================================")
    # print lettuces
    # print("=================================")
    # for (x,y,w,h) in lettuces:
    #     cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)

    return lettuces


def bounding_box_to_hypothesis(bounding_box):
    # global Last_lettuce_id
    # Last_lettuce_id = Last_lettuce_id + 1
    # return [str(Last_lettuce_id), bounding_box, 'healthy', 0.8]    
    return LettuceHypothesisComplete(bounding_box, DEFAULT_FAKE_LABEL, DEFAULT_FAKE_PROBABILITY)

def annotate_image(image, hypotheses):
    for hypothesis_2D in hypotheses:
        # lettuce_id = hypothesis_2D[0]
        # x = hypothesis_2D[1][0]
        # y = hypothesis_2D[1][1]
        # w = hypothesis_2D[1][2]
        # h = hypothesis_2D[1][3]
        # # To do: show ID, label and probability
        # label = hypothesis_2D[1]
        # probability = hypothesis_2D[2]
        rgb_color = (255,0,0)
        x = hypothesis_2D.x2D()
        y = hypothesis_2D.y2D()
        w = hypothesis_2D.w2D()
        h = hypothesis_2D.h2D()

        cv2.rectangle(image,(x,y),(x+w,y+h),rgb_color,2)
    return image

def transform_2D_hypothesis_to_3D(hypothesis_2D):
    #x3D = point_2D_to_point_3D()
    return None        
 
def image_to_image_message(image):
    return OpenCVBridge.cv2_to_imgmsg(image, "rgb8")

def image_message_to_cv2_image(image):
    return OpenCVBridge.imgmsg_to_cv2(image)

def publish_camera_projection():
    pass   

##################################################################################

########################### LettuceHypothesisComplete ############################

class LettuceHypothesisComplete:
    def __init__(self, bounding_box, label=DEFAULT_FAKE_LABEL, probability=DEFAULT_FAKE_PROBABILITY, lettuce_id=None):
        global Last_lettuce_id
        self.bounding_box = bounding_box
        self.label = label
        self.probability = probability
        if (lettuce_id==None):
            Last_lettuce_id = Last_lettuce_id + 1
            self.lettuce_id = Last_lettuce_id
        else:
            self.lettuce_id = lettuce_id
        #self.calculate_3D_position()
        if ((USE_CALIBRATION_RECORDS) and (Latest_calibration_records!=None)):
            self.calculate_3D_position_from_calibration_plane(Latest_calibration_records)
            return
        self.calculate_3D_position_from_model()

    def lettuce_id(self):
        return self.lettuce_id    

    def x2D(self):
        return self.bounding_box[0]

    def y2D(self):
        return self.bounding_box[1]

    def w2D(self):
        return self.bounding_box[2]

    def h2D(self):
        return self.bounding_box[3]

    def centre_of_bounding_box_x(self):
        return self.x2D() + self.w2D() / 2.0  

    def centre_of_bounding_box_y(self):
        return self.y2D() + self.h2D() / 2.0  

    def label(self):
        return self.label

    def probability(self):
        return self.probability

    def calculate_3D_position(self):
        if not hasattr(self, 'lettuce_id'):
            print("*** WARNING: LettuceHypothesis not properly created ****")             
        # print("Calculating 3D position")
        self.centre_x = self.x2D() + self.w2D() / 2
        self.centre_y = self.y2D() + self.h2D() / 2
        self.radius3D = points2D_to_distance3D(self.x2D(), self.y2D(), 
                                               self.x2D()+self.w2D(), 
                                               self.y2D()+self.h2D()) / 2.0
        #rospy.loginfo("calculate_3D_pos")
        #self.centre3D = point_2D_to_point_3D(self.x2D(), self.y2D())
        self.centre3D = point_2D_to_point_3D(self.centre_x, self.centre_y)
        self.centre3D.point.z = self.centre3D.point.z + self.radius3D        


        # print("Calculating 3D position")
        self.centre_x = self.x2D() + self.w2D() / 2
        self.centre_y = self.y2D() + self.h2D() / 2
        self.radius3D = points2D_to_distance3D(self.x2D(), self.y2D(), 
                                               self.x2D()+self.w2D(), 
                                               self.y2D()+self.h2D()) / 2.0
        #rospy.loginfo("calculate_3D_pos")
        #self.centre3D = point_2D_to_point_3D(self.x2D(), self.y2D())
        self.centre3D = point_2D_to_point_3D(self.centre_x, self.centre_y)
        self.centre3D.point.z = self.centre3D.point.z + self.radius3D

    def calculate_3D_position_from_model(self):
        if not hasattr(self, 'lettuce_id'):
            print("*** WARNING: LettuceHypothesis not properly created ****")             
        # print("Calculating 3D position")

        self.centre_x = self.centre_of_bounding_box_x()
        self.centre_y = self.centre_of_bounding_box_y()
        self.centre3D = point_2D_to_point_3D_using_camera_model(self.centre_x, self.centre_y)
        # TODO> Make this real
        self.radius3D = 0.08


        # self.centre_x = self.x2D() + self.w2D() / 2
        # self.centre_y = self.y2D() + self.h2D() / 2
        # self.radius3D = points2D_to_distance3D(self.x2D(), self.y2D(), 
        #                                        self.x2D()+self.w2D(), 
        #                                        self.y2D()+self.h2D()) / 2.0
        # rospy.loginfo("calculate_3D_pos")
        # #self.centre3D = point_2D_to_point_3D(self.x2D(), self.y2D())
        # self.centre3D = point_2D_to_point_3D(self.centre_x, self.centre_y)
        # self.centre3D.point.z = self.centre3D.point.z + self.radius3D        


        # # print("Calculating 3D position")
        # self.centre_x = self.x2D() + self.w2D() / 2
        # self.centre_y = self.y2D() + self.h2D() / 2
        # self.radius3D = points2D_to_distance3D(self.x2D(), self.y2D(), 
        #                                        self.x2D()+self.w2D(), 
        #                                        self.y2D()+self.h2D()) / 2.0
        # rospy.loginfo("calculate_3D_pos")
        # #self.centre3D = point_2D_to_point_3D(self.x2D(), self.y2D())
        # self.centre3D = point_2D_to_point_3D(self.centre_x, self.centre_y)
        # self.centre3D.point.z = self.centre3D.point.z + self.radius3D

    def calculate_3D_position_from_calibration_plane(self, records):
        rospy.loginfo("Using calibration plane")
        self.centre_x = self.centre_of_bounding_box_x()
        self.centre_y = self.centre_of_bounding_box_y()
        (x,y,z) = self.convert_2D_to_3D_in_calibration_plane(records, self.centre_x, self.centre_y)
        point = PointStamped()
        point.header.stamp = rospy.Time.now()
        point.header.frame_id = 'camera_link'
        point.point.x = x
        point.point.y = y 
        point.point.z = z
        rospy.loginfo("------------------------")
        rospy.loginfo(x)
        rospy.loginfo(y)
        rospy.loginfo(z)
        rospy.loginfo("------------------------")
        self.centre3D = point
        self.radius3D = 0.08

    def convert_2D_to_3D_in_calibration_plane(self, records, ut, vt):
        #rospy.loginfo("*****************************")
        #rospy.loginfo(records)
        #rospy.loginfo("*****************************")
        x0 = records.x0
        y0 = records.y0
        z0 = records.z0
        u0 = records.u0
        v0 = records.v0

        x1 = records.x1
        y1 = records.y1
        z1 = records.z1
        u1 = records.u1
        v1 = records.v1

        x2 = records.x2
        y2 = records.y2
        z2 = records.z2
        u2 = records.u2
        v2 = records.v2
        # Now transform u1,v1 and u2,v2 to be wrt to u0,v0 i.e. vectors from u0,v0
        uu1 = u1 - u0
        vv1 = v1 - v0
        uu2 = u2 - u0
        vv2 = v2 - v0
        # Target wrt u0,v0
        uut = ut - u0
        vvt = vt - v0
        # Now get a, b scaling factors where
        # a[uu1, vv1]T + b[uu2, vv2]T = [uut, vvt]T
        b = (vvt-(uut/uu1)*vv1) / (vv2 - (uu2/uu1)*vv1)
        a = (uut-b*uu2) / uu1
        # Now get equivalent 3D vectors wrt x0,y0,z0
        xx1 = x1 - x0
        yy1 = y1 - y0
        zz1 = z1 - z0
        xx2 = x2 - x0
        yy2 = y2 - y0
        zz2 = z2 - z0
        # multiply by scaling factors
        xt = a * xx1 + b * xx2 + x0
        yt = a * yy1 + b * yy2 + y0
        zt = a * zz1 + b * zz2 + z0
        # Offset of Aruco Code from centre
        xt += ARUCO_OFFSET_X
        yt += ARUCO_OFFSET_Y
        return (xt, yt, zt)

    def radius3D(self):
        return self.radius3D

    def centre3D(self):
        return self.centre3D    

    def publish(self):
        global lettuce_hypothesis_topic
        lettuce_hypothesis_message = LettuceHypothesis()
        pose = Pose()
        pose.position.x = self.centre3D.point.x
        pose.position.y = self.centre3D.point.y
        pose.position.z = self.centre3D.point.z
        lettuce_id = str(self.lettuce_id)
        lettuce_hypothesis_message.lettuce_hypothesis_id = lettuce_id
        lettuce_hypothesis_message.label = 'lettuce_' + lettuce_id
        lettuce_hypothesis_message.pose = pose
        lettuce_hypothesis_message.radius = self.radius3D
        lettuce_hypothesis_message.probability = DEFAULT_FAKE_PROBABILITY

        lettuce_hypothesis_message.camera_bb_x = self.centre_x / float(FIELD_PIXEL_WIDTH)
        lettuce_hypothesis_message.camera_bb_y = self.centre_y / float(FIELD_PIXEL_HEIGHT)
        lettuce_hypothesis_message.camera_bb_width = self.w2D() / float(FIELD_PIXEL_WIDTH)
        lettuce_hypothesis_message.camera_bb_height = self.h2D() / float(FIELD_PIXEL_HEIGHT)

        Lettuce_hypothesis_topic.publish(lettuce_hypothesis_message)
        rospy.loginfo(lettuce_hypothesis_message)
            

##################################################################################

########################### 3D Geometry ##########################################

def point_2D_to_point_3D_using_camera_model(x2D, y2D):
    global Overhead_camera_model

    ray_in_camera_frame = unit_vector_to_target_in_camera_frame(x2D, y2D)
    plane_points_camera_frame = ground_plane_points_in_camera_frame()
    intersection_camera_frame = intersection_vector_and_plane(ray_in_camera_frame, plane_points_camera_frame)
    intersection_world_frame = point_in_camera_frame_to_world_frame(intersection_camera_frame[0], intersection_camera_frame[1], intersection_camera_frame[2])
    #rospy.loginfo("Intersection in world frame")
    #rospy.loginfo(intersection_world_frame)
    return intersection_world_frame

def unit_vector_to_target_in_camera_frame(x2D, y2D):    
    global Overhead_camera_model

    # rospy.loginfo("Raw u,v")
    # rospy.loginfo(x2D)
    # rospy.loginfo(y2D)
    # TODO: Multiple camera frames
    (rectified_x, rectified_y) = Overhead_camera_model.rectifyPoint((x2D, y2D))
    # rospy.loginfo("Rectified u, v")
    # rospy.loginfo(rectified_x)
    # rospy.loginfo(rectified_y)
    ray = Overhead_camera_model.projectPixelTo3dRay((rectified_x, rectified_y))
    # Transform from opencv coordinates to conventional camera coordinates

    ros_ray = [ray[2], -ray[0], -ray[1]]
    # rospy.loginfo("ROS Ray")
    # rospy.loginfo(ray)

    return ros_ray

def ground_plane_points_in_camera_frame():
    point0_camera = point_in_world_frame_to_camera_frame(0.0, 0.0, 0.0)
    point1_camera = point_in_world_frame_to_camera_frame(10.0, 10.0, 0.0)
    point2_camera = point_in_world_frame_to_camera_frame(-10.0, 10.0, 0.0)
    return [point0_camera, point1_camera, point2_camera]

def intersection_vector_and_plane(vector, plane_stamped_points):
    # rospy.loginfo("intersection_vector_and_plane(vector, plane_stamped_points)")
    # rospy.loginfo("Vector")
    # rospy.loginfo(vector)
    plane_points = [0.0, 0.0, 0.0]
    plane_points[0] = plane_stamped_points[0].point
    plane_points[1] = plane_stamped_points[1].point
    plane_points[2] = plane_stamped_points[2].point
    # rospy.loginfo("plane_points")
    # rospy.loginfo(plane_points)

    # xa, ya, za = end of vector. xb, yb, zb = origin
    matrix = numpy.array([[vector[0], plane_points[1].x-plane_points[0].x, plane_points[2].x-plane_points[0].x],
                          [vector[1], plane_points[1].y-plane_points[0].y, plane_points[2].y-plane_points[0].y],
                          [vector[2], plane_points[1].z-plane_points[0].z, plane_points[2].z-plane_points[0].z]])
    try:
        inverse = numpy.linalg.inv(matrix)
    except numpy.linalg.LinAlgError:
        # Not invertible. Skip this one.
        rospy.loginfo("**** ERROR ****: Couldnt invert matrix in intersection_vector_and_plane().") 
        quit()   
    matrix2 = numpy.array( [[vector[0] - plane_points[0].x],
                            [vector[1] - plane_points[0].y],
                            [vector[2] - plane_points[0].z]])
    result = numpy.matmul(inverse, matrix2)
    t = result[0]
    intersection = vector * (1 - t)
    # rospy.loginfo("Intersection in camera frame")
    # rospy.loginfo(intersection)
    return intersection

def point_in_camera_frame_to_world_frame(x_camera, y_camera, z_camera):
    transform = get_camera_to_world_transform()
    point = transformed_point(x_camera, y_camera, z_camera, transform)
    return point    

def point_in_world_frame_to_camera_frame(x_world, y_world, z_world):
    transform = get_world_to_camera_transform()
    point = transformed_point(x_world, y_world, z_world, transform)
    return point    

def point_2D_to_point_3D(x2D, y2D):
    global FIELD_WIDTH_ANGLE, FIELD_HEIGHT_ANGLE

    x = x2D
    y = y2D

    # rospy.loginfo("$===========")
    # rospy.loginfo(x2D)
    # rospy.loginfo(y2D)
    # rospy.loginfo("$===========")
    # rospy.loginfo("Field widths:")
    # rospy.loginfo(FIELD_WIDTH_ANGLE)
    # rospy.loginfo(FIELD_HEIGHT_ANGLE)

    camera_transform = get_camera_to_world_transform()
    distance_to_floor = camera_transform.transform.translation.z
    field_width = 2.0 * distance_to_floor * math.tan(math.radians(FIELD_WIDTH_ANGLE) / 2.0)
    half_field_width = field_width / 2.0
    field_height = 2.0 * distance_to_floor * math.tan(math.radians(FIELD_HEIGHT_ANGLE) / 2.0)
    half_field_height = field_height / 2.0

    FUDGE = 0.10

    # x,y relative to top left of camera field
    x3D = distance_to_floor
    z3D = (half_field_width - (field_width * x / FIELD_PIXEL_WIDTH))
    y3D = -(half_field_height - (field_height * y / FIELD_PIXEL_HEIGHT)) #+ FUDGE

    point_in_world = transformed_point(x3D, y3D, z3D, camera_transform)
    return point_in_world

def camera_field_polygon_in_world():
    global FIELD_WIDTH_ANGLE, FIELD_HEIGHT_ANGLE
    # rospy.loginfo("$$$$$$$$$$$$$$$$$$")
    # rospy.loginfo(FIELD_WIDTH_ANGLE)
    # rospy.loginfo("$$$$$$$$$$$$$$$$$$")
    
    camera_transform = get_camera_to_world_transform()
    distance_to_floor = 0 - camera_transform.transform.translation.z
    field_width = 2.0 * distance_to_floor * math.tan(math.radians(FIELD_WIDTH_ANGLE / 2.0))
    half_field_width = field_width / 2.0
    field_height = 2.0 * distance_to_floor * math.tan(math.radians(FIELD_HEIGHT_ANGLE / 2.0))
    half_field_height = field_height / 2.0

    top_left_world = transformed_point(distance_to_floor, half_field_width, half_field_height, camera_transform)
    top_right_world = transformed_point(distance_to_floor, -half_field_width, half_field_height, camera_transform)
    bottom_left_world = transformed_point(distance_to_floor, half_field_width, -half_field_height, camera_transform)
    top_left_world = transformed_point(distance_to_floor, -half_field_width, -half_field_height, camera_transform)
    return


def transformed_point(x, y, z, transform):
    point = PointStamped()
    point.header.stamp = rospy.Time.now()
    point.header.frame_id = 'camera_link'
    point.point.x = x
    point.point.y = y 
    point.point.z = z
    point_in_world = tf2_geometry_msgs.do_transform_point(point, transform)
    return point_in_world

def points2D_to_distance3D(x1,y1,x2,y2):
    point1 = point_2D_to_point_3D(x1, y1)
    point2 = point_2D_to_point_3D(x2, y2)

    distance = math.sqrt((point1.point.x - point2.point.x)**2 + 
                         (point1.point.y - point2.point.y)**2 + 
                         (point1.point.z - point2.point.z)**2)
    return distance    

def initialize_camera_params():
    rospy.set_param(FIELD_WIDTH_ANGLE_PARAM, FIELD_WIDTH_ANGLE)
    rospy.set_param(FIELD_HEIGHT_ANGLE_PARAM, FIELD_HEIGHT_ANGLE)


##################################################################################

if __name__ == '__main__':
    print("Launching lettuce detector...")
    subscribe_to_camera_info()
    initialize_camera_params()
    rospy.init_node(NODE_NAME, anonymous=True)
    subscribe_to_transforms()
    set_up_opencv()
    set_up_lettuce_hypotheses_topic()
    set_up_lettuce_images_annotated_topic()
    set_up_marker_corners_topic()
    set_up_calibration_records_topic()
    subscribe_to_lettuce_images_raw_topic(process_incoming_image)
    subscribe_to_lettuce_updates_from_viewport()

    try:
        rospy.spin()
    except KeyboardInterrupt:
        print "Shutting down lettuce detector"
    cv2.destroyAllWindows()